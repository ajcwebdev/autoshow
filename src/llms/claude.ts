// src/llms/claude.ts

import Anthropic from '@anthropic-ai/sdk'
import { err } from '../utils/logging.ts'
import { env } from '../utils/node-utils.ts'
import { LLM_SERVICES_CONFIG } from '../../shared/constants.ts'
import { checkLLMApiKey, buildCombinedPrompt } from '../utils/llm-service-utils.ts'

export type ClaudeModelValue = (typeof LLM_SERVICES_CONFIG.claude.models)[number]['modelId']

export async function callClaude(
  prompt: string,
  transcript: string,
  modelValue: ClaudeModelValue
) {
  checkLLMApiKey('claude')

  const anthropic = new Anthropic({ apiKey: env['ANTHROPIC_API_KEY'] })
  const combinedPrompt = buildCombinedPrompt(prompt, transcript)

  try {
    const res = await anthropic.messages.create({
      model: modelValue,
      max_tokens: 4000,
      messages: [
        { role: 'user', content: combinedPrompt }
      ]
    })
    const firstBlock = res.content?.[0]
    if (!firstBlock || firstBlock.type !== 'text') {
      throw new Error('No valid text content generated by Claude.')
    }
    return {
      content: firstBlock.text,
      usage: {
        stopReason: res.stop_reason ?? 'unknown',
        input: res.usage?.input_tokens,
        output: res.usage?.output_tokens,
        total: (res.usage?.input_tokens ?? 0) + (res.usage?.output_tokens ?? 0)
      }
    }
  } catch (error) {
    err(`Error in callClaude: ${(error as Error).message}`)
    throw error
  }
}
